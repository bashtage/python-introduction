{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression: Tree-based Methods\n",
    "\n",
    "\n",
    "**Functions**\n",
    "\n",
    "`sklearn.ensemble.RandomForestRegressor`, `sklearn.model_selection.GridSearchCV`, `sklearn.ensemble.GradientBoostingRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:24.839902Z",
     "iopub.status.busy": "2021-09-22T10:07:24.838900Z",
     "iopub.status.idle": "2021-09-22T10:07:26.470902Z",
     "shell.execute_reply": "2021-09-22T10:07:26.470902Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.api import OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 59\n",
    "\n",
    "Load the portfolio tracking data and compute the in- and out-of-sample SSE for OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.474900Z",
     "iopub.status.busy": "2021-09-22T10:07:26.474900Z",
     "iopub.status.idle": "2021-09-22T10:07:26.517902Z",
     "shell.execute_reply": "2021-09-22T10:07:26.517902Z"
    }
   },
   "outputs": [],
   "source": [
    "vwm = pd.read_csv(\"data/VWM.csv\", index_col=\"Date\")\n",
    "vwm.index = pd.to_datetime(vwm.index, format=\"%Y%m\")\n",
    "vwm = vwm.resample(\"M\").last()\n",
    "\n",
    "industries = pd.read_csv(\"data/12_Industry_portfolios.csv\", index_col=\"Date\")\n",
    "industries.index = pd.to_datetime(industries.index, format=\"%Y%m\")\n",
    "industries = industries.resample(\"M\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.520900Z",
     "iopub.status.busy": "2021-09-22T10:07:26.520900Z",
     "iopub.status.idle": "2021-09-22T10:07:26.533627Z",
     "shell.execute_reply": "2021-09-22T10:07:26.533627Z"
    }
   },
   "outputs": [],
   "source": [
    "x = industries[\"1980\":\"2014\"]\n",
    "y = vwm[\"VWM\"][\"1980\":\"2014\"]\n",
    "t, p = x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "We first show the OLS in-sample SSE as a benchmark value, and then its out-of-sample SSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.540623Z",
     "iopub.status.busy": "2021-09-22T10:07:26.536623Z",
     "iopub.status.idle": "2021-09-22T10:07:26.548596Z",
     "shell.execute_reply": "2021-09-22T10:07:26.548596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS SSE is 134.5\n"
     ]
    }
   ],
   "source": [
    "tss = y.T @ y\n",
    "res = OLS(y, x).fit()\n",
    "print(f\"OLS SSE is {tss * (1-res.rsquared):0.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.553595Z",
     "iopub.status.busy": "2021-09-22T10:07:26.553595Z",
     "iopub.status.idle": "2021-09-22T10:07:26.563760Z",
     "shell.execute_reply": "2021-09-22T10:07:26.563760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample SSE for OLS is 20.15\n"
     ]
    }
   ],
   "source": [
    "# Select the out-of-sample data\n",
    "y_oos = vwm.loc[\"2015\":, \"VWM\"]\n",
    "x_oos = industries[\"2015\":]\n",
    "\n",
    "resid = y_oos - x_oos @ res.params\n",
    "ols_oos_sse = resid.T @ resid\n",
    "print(f\"The out-of-sample SSE for OLS is {ols_oos_sse:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 60\n",
    "\n",
    "Fit a default Random Forest in a reproducible manner to the portfolio tracking data and compute the in- and out-of-sample SSE.\n",
    "\n",
    "**Warning**: This exercise is simply an example of how to use these methods. In general tree-based models are terrible choices for tracking portfolio construction since the final model is not a weighted combination of the returns, but instead depends on non-linear transformation of the returns. This makes implementation of a tree-based estimator virtually impossible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "Random Forests fit ensembles of trees (combinations) using a random sample of the regressors in each.  Here we fit a default Random Forest where we use the $\\sqrt{p}$ rule for feature selection within each tree. The should reduce the correlation between trees.\n",
    "\n",
    "The in-sample SSE is very good and much smaller than the in-sample SSE of OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.591758Z",
     "iopub.status.busy": "2021-09-22T10:07:26.567758Z",
     "iopub.status.idle": "2021-09-22T10:07:26.706759Z",
     "shell.execute_reply": "2021-09-22T10:07:26.706759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RandomForest SSE is 62.9\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(max_features=\"sqrt\", random_state=20201231)\n",
    "rfr = rfr.fit(x, y)\n",
    "resid = y - rfr.predict(x)\n",
    "print(f\"The RandomForest SSE is {resid.T@resid:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "The out-of-sample SSE, however, is quite a bit worse than OLS.  Tree-based models are not good models for tracking portfolio construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.710758Z",
     "iopub.status.busy": "2021-09-22T10:07:26.710758Z",
     "iopub.status.idle": "2021-09-22T10:07:26.722758Z",
     "shell.execute_reply": "2021-09-22T10:07:26.722758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample SSE for the default RF is 33.93\n"
     ]
    }
   ],
   "source": [
    "pred = rfr.predict(x_oos)\n",
    "resid = y_oos - pred\n",
    "rf_oos_sse = resid.T @ resid\n",
    "print(f\"The out-of-sample SSE for the default RF is {rf_oos_sse:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 61\n",
    "\n",
    "Optimize the key tuning parameters of the Random Forest using cross-validation and compute the out-of-sample SSE of the preferred model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:26.726757Z",
     "iopub.status.busy": "2021-09-22T10:07:26.726757Z",
     "iopub.status.idle": "2021-09-22T10:07:39.517279Z",
     "shell.execute_reply": "2021-09-22T10:07:39.517279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": [100, 250, 500, 1000],\n",
    "    \"max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"max_leaf_nodes\": [50, 100, 200, 225, 250],\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=20201231)\n",
    "gscv = GridSearchCV(\n",
    "    rfr, parameters, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "gscv = gscv.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "`GridSearchCV` allows us to compute the cross-validated score of a model for a combination of input parameters. This method is similar to writing a number of loops across each of the parameters and then cross-validating the model for each distinct combination.  \n",
    "\n",
    "The key input to `GridSearchCV` is a dictionary where the keys are model parameter names and the values are the values that should be considered in the search.  The model is then automatically cross-validated for all of combinations of the parameters. \n",
    "\n",
    "**Note**: This cell may run of an extended period, depending on your system.\n",
    "\n",
    "The best estimator in the sense of minimizing the score function (negative MSE here) is available using the `best_estimator_` attribute. This is a `RandomForestRegressor` with the CV-optimized parameters. This estimator can then be fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:39.637277Z",
     "iopub.status.busy": "2021-09-22T10:07:39.637277Z",
     "iopub.status.idle": "2021-09-22T10:07:40.115278Z",
     "shell.execute_reply": "2021-09-22T10:07:40.115278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', max_leaf_nodes=225, n_estimators=500,\n",
       "                      random_state=20201231)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_best = gscv.best_estimator_.fit(x, y)\n",
    "rfr_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:40.119277Z",
     "iopub.status.busy": "2021-09-22T10:07:40.119277Z",
     "iopub.status.idle": "2021-09-22T10:07:40.178277Z",
     "shell.execute_reply": "2021-09-22T10:07:40.178277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The in-sample SSE of the best model is 58.2\n"
     ]
    }
   ],
   "source": [
    "resid = y - rfr_best.predict(x)\n",
    "print(f\"The in-sample SSE of the best model is {resid.T @ resid:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "The in-sample SSE is very good, and is slightly better than the naive attempt.\n",
    "\n",
    "Note that the cross-validated sse is related to the negative MSE usign the relationship\n",
    "\n",
    "$$ \\text{Neg MSE} = -\\frac{SSE_{xv}}{n} $$\n",
    "\n",
    "The values are stored in a dictionary `gscv.cv_results_` using the key `\"mean_test_score\"`.  We can convert these to cross-validated SSE for comparison with other methods. These are all higher than what we saw with regression methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:40.182280Z",
     "iopub.status.busy": "2021-09-22T10:07:40.181276Z",
     "iopub.status.idle": "2021-09-22T10:07:40.193277Z",
     "shell.execute_reply": "2021-09-22T10:07:40.193277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([543.45130064, 542.35097801, 538.82874551, 539.14500168,\n",
       "       524.50255337, 523.72519581, 520.97157683, 521.23190854,\n",
       "       523.24923978, 522.95215578, 520.43702707, 520.6435387 ,\n",
       "       523.23792766, 522.94174719, 520.4335865 , 520.63867577,\n",
       "       523.23792766, 522.94174719, 520.4335865 , 520.63867577,\n",
       "       513.04864491, 510.34144513, 507.68919293, 512.52868972,\n",
       "       498.21866735, 492.91300459, 490.63116003, 494.97361627,\n",
       "       497.82659792, 492.46257337, 489.54352418, 493.0663823 ,\n",
       "       497.82127479, 492.45466584, 489.52822532, 493.05273718,\n",
       "       497.82127479, 492.45466584, 489.52822867, 493.05273887])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse_xv = -t * gscv.cv_results_[\"mean_test_score\"]\n",
    "sse_xv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "`cv_results_` also contains the parameters used in each configuration. Here we can build a `DataFrame` that examines the better parameterizations by merging these values with the $SSE_{xv}$ and sorting.  We see that the best configurations always used `\"sqrt\"` for `max_features`, and the 500 consistently outperformed 250 or 1000 estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:40.198280Z",
     "iopub.status.busy": "2021-09-22T10:07:40.198280Z",
     "iopub.status.idle": "2021-09-22T10:07:40.209278Z",
     "shell.execute_reply": "2021-09-22T10:07:40.209278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>sse_xv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>225</td>\n",
       "      <td>500</td>\n",
       "      <td>489.528225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>489.528229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>489.543524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>490.631160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>492.454666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>225</td>\n",
       "      <td>250</td>\n",
       "      <td>492.454666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>250</td>\n",
       "      <td>492.462573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>250</td>\n",
       "      <td>492.913005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>225</td>\n",
       "      <td>1000</td>\n",
       "      <td>493.052737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>1000</td>\n",
       "      <td>493.052739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  max_leaf_nodes  n_estimators      sse_xv\n",
       "34         sqrt             225           500  489.528225\n",
       "38         sqrt             250           500  489.528229\n",
       "30         sqrt             200           500  489.543524\n",
       "26         sqrt             100           500  490.631160\n",
       "37         sqrt             250           250  492.454666\n",
       "33         sqrt             225           250  492.454666\n",
       "29         sqrt             200           250  492.462573\n",
       "25         sqrt             100           250  492.913005\n",
       "35         sqrt             225          1000  493.052737\n",
       "39         sqrt             250          1000  493.052739"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(gscv.cv_results_[\"params\"])\n",
    "df[\"sse_xv\"] = sse_xv\n",
    "df.sort_values(\"sse_xv\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "Finally we can compute the OOS SSE using the `predict` method with the out-of-sample data. This value is poor when compared to OLS.  This indicates (not surprisingly) that tree-based methods are not good ways to fit financial return data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:40.213276Z",
     "iopub.status.busy": "2021-09-22T10:07:40.213276Z",
     "iopub.status.idle": "2021-09-22T10:07:40.256828Z",
     "shell.execute_reply": "2021-09-22T10:07:40.256828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample SSE for the optimized RF is 36.28\n"
     ]
    }
   ],
   "source": [
    "pred = rfr_best.predict(x_oos)\n",
    "resid = y_oos - pred\n",
    "rf_oos_sse = resid @ resid\n",
    "print(f\"The out-of-sample SSE for the optimized RF is {rf_oos_sse:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 62\n",
    "\n",
    "Boosting is often a better alternative to Random Forests sine it limits tree depth, and in turn, variable interactions. Fit a default boosted regression tree to the portfolio tracking data, and compute the out-of-sample SSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:40.261826Z",
     "iopub.status.busy": "2021-09-22T10:07:40.261826Z",
     "iopub.status.idle": "2021-09-22T10:07:40.368828Z",
     "shell.execute_reply": "2021-09-22T10:07:40.368828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.039847616420666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=20201231)\n",
    "gbr.fit(x, y)\n",
    "pred = gbr.predict(x_oos)\n",
    "resid = y_oos - pred\n",
    "gbr_oos_sse = resid @ resid\n",
    "gbr_oos_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "Here we fit a default boosted regression tree using `GradientBoostingRegressor`.  it is always a good idea to set `random_state` to ensure results are reproducible. We compute the OOS SSE and see that the default parameters perform well when compared to either Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 63\n",
    "\n",
    "Optimize the key parameters of the boosted regression tree using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:07:40.372830Z",
     "iopub.status.busy": "2021-09-22T10:07:40.372830Z",
     "iopub.status.idle": "2021-09-22T10:09:38.972363Z",
     "shell.execute_reply": "2021-09-22T10:09:38.972363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(random_state=20201231),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.025, 0.05, 0.1, 0.2],\n",
       "                         'max_leaf_nodes': [2, 3, 4, 6],\n",
       "                         'n_estimators': [1000, 2000, 4000, 8000, 12000]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.1, 0.2],\n",
    "    \"n_estimators\": [1000, 2000, 4000, 8000, 12000],\n",
    "    \"max_leaf_nodes\": [2, 3, 4, 6],\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    gbr, parameters, n_jobs=-1, scoring=\"neg_mean_squared_error\", verbose=1\n",
    ")\n",
    "gscv.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "Boosted models can be tuned like any other approach.  Here we use `GridSearchCV` again to search for good choices of the learning rate ($\\lambda$ in the notes), the number of estimators ($B$ in the notes), and the `max_leaf_nodes` ($d$ in the notes).\n",
    "\n",
    "**Note**: This cell can take a while to run, depending on your machine.\n",
    "\n",
    "The preferred configuration has a large number of estimators with a relatively low learning rate and small trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:09:38.979362Z",
     "iopub.status.busy": "2021-09-22T10:09:38.978362Z",
     "iopub.status.idle": "2021-09-22T10:09:45.784363Z",
     "shell.execute_reply": "2021-09-22T10:09:45.783364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.025, max_leaf_nodes=3,\n",
       "                          n_estimators=8000, random_state=20201231)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbr = gscv.best_estimator_.fit(x, y)\n",
    "best_gbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "When we look at the top performing estimators, we see that small trees combined, slow learning and many estimators consistently perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:09:45.792363Z",
     "iopub.status.busy": "2021-09-22T10:09:45.788365Z",
     "iopub.status.idle": "2021-09-22T10:09:45.798362Z",
     "shell.execute_reply": "2021-09-22T10:09:45.798362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>sse_xv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>8000</td>\n",
       "      <td>291.991080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>12000</td>\n",
       "      <td>292.238313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>12000</td>\n",
       "      <td>292.523746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025</td>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>294.850653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.050</td>\n",
       "      <td>3</td>\n",
       "      <td>12000</td>\n",
       "      <td>296.995546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050</td>\n",
       "      <td>3</td>\n",
       "      <td>8000</td>\n",
       "      <td>297.068889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050</td>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>297.568802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>8000</td>\n",
       "      <td>298.710714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>300.142419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>8000</td>\n",
       "      <td>306.097345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_leaf_nodes  n_estimators      sse_xv\n",
       "1           0.025               3          8000  291.991080\n",
       "2           0.025               3         12000  292.238313\n",
       "3           0.010               3         12000  292.523746\n",
       "4           0.025               3          4000  294.850653\n",
       "5           0.050               3         12000  296.995546\n",
       "6           0.050               3          8000  297.068889\n",
       "7           0.050               3          4000  297.568802\n",
       "8           0.010               3          8000  298.710714\n",
       "9           0.050               3          2000  300.142419\n",
       "10          0.025               2          8000  306.097345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sse_xv = -t * gscv.cv_results_[\"mean_test_score\"]\n",
    "df = pd.DataFrame(gscv.cv_results_[\"params\"])\n",
    "df[\"sse_xv\"] = sse_xv\n",
    "df = df.sort_values(\"sse_xv\")\n",
    "df.index = np.arange(1, df.shape[0] + 1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 64\n",
    "\n",
    "Compute the out-of-sample SSE for the selected boosted regression tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T10:09:45.807365Z",
     "iopub.status.busy": "2021-09-22T10:09:45.801362Z",
     "iopub.status.idle": "2021-09-22T10:09:45.814365Z",
     "shell.execute_reply": "2021-09-22T10:09:45.814365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.778563339935815"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = best_gbr.predict(x_oos)\n",
    "resid = y_oos - pred\n",
    "rf_oos_sse = resid @ resid\n",
    "rf_oos_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation \n",
    "\n",
    "We can generate the out-of-sample SSE for the optimized GBR. We see that while it is substantially improved over what we found with a Regression Tree, it is still 15% worse then what plain OLS achieves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
