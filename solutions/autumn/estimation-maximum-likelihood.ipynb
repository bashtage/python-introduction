{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Maximum Likelihood Estimation\n",
    "\n",
    "**Functions**\n",
    "\n",
    "`np.log`, `scipy.special.gamma`, `scipy.special.gammaln`, `scipy.stats.norm.cdf`, `scipy.optimize.minimize`,\n",
    "`scipy.stats.t`, `np.var`, `np.std`, `scipy.stats.norm.pdf`\n",
    "\n",
    "### Exercise 20\n",
    "\n",
    "Simulate a set of i.i.d. Student's t random variables with degree of freedom\n",
    "parameter $\\nu=10$. Standardize the residuals so that they have unit variance\n",
    "using the fact that $V\\left[x \\right]=\\frac{\\nu}{\\nu-2}$. Use these to estimate\n",
    "the degree of freedom using maximum likelihood. Note that the likelihood of\n",
    "a standardized Student's t is\n",
    "\n",
    "$$f(x;\\nu,\\mu,\\sigma^{2})=\\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)}\\,\\frac{1}{\\sqrt{\\pi(\\nu-2)}}\\,\\frac{1}{\\sigma}\\,\\frac{1}{\\left(1+\\frac{\\left(x-\\mu\\right)^{2}}{\\sigma^{2}(\\nu-2)}\\right)^{\\frac{\\nu+1}{2}}}$$\n",
    "\n",
    "where $\\Gamma\\left(\\right)$ is known as the gamma function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance is 1.0435286272711175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rs = np.random.RandomState(19991231)\n",
    "var = 10 / (10 - 2)\n",
    "rvs = rs.standard_t(10, size=1000) / np.sqrt(var)\n",
    "print(f\"The variance is {rvs.var()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log like at the population nu is 1435.8970961055188\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import gammaln\n",
    "\n",
    "\n",
    "def std_t_loglik(nu, x):\n",
    "    # These are fixed for now\n",
    "    mu = 0\n",
    "    sigma2 = 1\n",
    "    sigma = np.sqrt(sigma2)\n",
    "\n",
    "    a = gammaln((nu + 1) / 2)\n",
    "    b = gammaln(nu / 2)\n",
    "    c = np.sqrt(np.pi * (nu - 2))\n",
    "    d = (nu + 1) / 2\n",
    "    e = (x - mu) ** 2\n",
    "    f = sigma2 * (nu - 2)\n",
    "\n",
    "    loglik = a - b - np.log(c) - np.log(sigma) - d * np.log(1 + e / f)\n",
    "    return -(loglik.sum())\n",
    "\n",
    "\n",
    "print(f\"The log like at the population nu is {std_t_loglik(10, rvs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLE is 12.651889299251675 and the optimized (negative) LLF is 1435.6002952027727\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "starting_val = np.array([10])\n",
    "opt = minimize(\n",
    "    std_t_loglik,\n",
    "    starting_val,\n",
    "    args=(rvs,),\n",
    "    bounds=[(2.05, 100)],\n",
    ")\n",
    "print(f\"The MLE is {opt.x[0]} and the optimized (negative) LLF is {opt.fun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 21\n",
    "\n",
    "Repeat the previous exercise using daily, weekly and monthly S&P 500 and Hang Seng data.\n",
    "Note that it is necessary to remove the mean and standardize by the standard deviation\n",
    "error before estimating the degree of freedom. What happens over longer horizons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLE is 3.343618972523551 and the optimized (negative) LLF is 22731.853179025893\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prices = pd.read_hdf(\"data/equity-indices.h5\", \"sp500\")\n",
    "rets = 100 * prices.Close.pct_change().dropna()\n",
    "\n",
    "std_rets = (rets - rets.mean()) / rets.std()\n",
    "starting_val = np.array([10])\n",
    "opt = minimize(\n",
    "    std_t_loglik,\n",
    "    starting_val,\n",
    "    args=(std_rets,),\n",
    "    bounds=[(2.05, 100)],\n",
    ")\n",
    "print(f\"The MLE is {opt.x[0]} and the optimized (negative) LLF is {opt.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sp500, the MLE is 3.343618972523551 and the optimized (negative) LLF is 22731.853179025893\n",
      "For weekly_sp500, the MLE is 4.877074922965989 and the optimized (negative) LLF is 4948.088538563643\n",
      "For monthly_sp500, the MLE is 7.195810333221021 and the optimized (negative) LLF is 1169.4687637811821\n",
      "For hsi, the MLE is 3.343618972523551 and the optimized (negative) LLF is 22731.853179025893\n",
      "For weekly_hsi, the MLE is 3.877025093756984 and the optimized (negative) LLF is 2270.538188606181\n",
      "For monthly_hsi, the MLE is 4.299861670594397 and the optimized (negative) LLF is 531.4943348983943\n"
     ]
    }
   ],
   "source": [
    "keys = [\"sp500\", \"weekly_sp500\", \"monthly_sp500\", \"hsi\", \"weekly_hsi\", \"monthly_hsi\"]\n",
    "for key in keys:\n",
    "    prices = pd.read_hdf(\"data/equity-indices.h5\", key)\n",
    "    rets = 100 * prices.Close.pct_change().dropna()\n",
    "\n",
    "    std_rets = (rets - rets.mean()) / rets.std()\n",
    "    starting_val = np.array([10])\n",
    "    opt = minimize(\n",
    "        std_t_loglik,\n",
    "        starting_val,\n",
    "        args=(std_rets,),\n",
    "        bounds=[(2.05, 100)],\n",
    "    )\n",
    "    print(\n",
    "        f\"For {key}, the MLE is {opt.x[0]} and the optimized (negative) LLF is {opt.fun}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 22\n",
    "\n",
    "Repeat the previous problem by estimating the mean and variance simultaneously with\n",
    "the degree of freedom parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def full_std_t_loglik(parameters, x):\n",
    "    # These are fixed for now\n",
    "    mu = parameters[0]\n",
    "    sigma2 = parameters[1]\n",
    "    nu = parameters[2]\n",
    "    sigma = np.sqrt(sigma2)\n",
    "\n",
    "    a = gammaln((nu + 1) / 2)\n",
    "    b = gammaln(nu / 2)\n",
    "    c = np.sqrt(np.pi * (nu - 2))\n",
    "    d = (nu + 1) / 2\n",
    "    e = (x - mu) ** 2\n",
    "    f = sigma2 * (nu - 2)\n",
    "\n",
    "    loglik = a - b - np.log(c) - np.log(sigma) - d * np.log(1 + e / f)\n",
    "    return -(loglik.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(22751.09755414748)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = pd.read_hdf(\"data/equity-indices.h5\", \"sp500\")\n",
    "rets = 100 * prices.Close.pct_change().dropna()\n",
    "\n",
    "mean = rets.mean()\n",
    "var = rets.var()\n",
    "starting_val = np.array([mean, var, 10])\n",
    "full_std_t_loglik(starting_val, rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLE is [0.04885903 1.01908841 3.11732083] and the optimized (negative) LLF is 22034.20166114379\n"
     ]
    }
   ],
   "source": [
    "bounds = [(-10 * np.abs(mean), 10 * np.abs(mean)), (var / 1000, 100 * var), (2.05, 100)]\n",
    "opt = minimize(\n",
    "    full_std_t_loglik, starting_val, args=(rets,), bounds=bounds\n",
    ")\n",
    "print(f\"The MLE is {opt.x} and the optimized (negative) LLF is {opt.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sp500, the MLE is [0.04885903 1.01908841 3.11732083] and the optimized (negative) LLF is 22034.20166114379\n",
      "For weekly_sp500, the MLE is [0.22792143 4.3108545  4.96483093] and the optimized (negative) LLF is 7646.416875196425\n",
      "For monthly_sp500, the MLE is [ 0.83032671 16.92281463  6.99676976] and the optimized (negative) LLF is 2351.2108045736795\n",
      "For hsi, the MLE is [0.04885903 1.01908841 3.11732083] and the optimized (negative) LLF is 22034.20166114379\n",
      "For weekly_hsi, the MLE is [ 0.29490792 13.18062062  3.81009095] and the optimized (negative) LLF is 4459.737446193084\n",
      "For monthly_hsi, the MLE is [ 1.00200731 55.00104273  4.23244886] and the optimized (negative) LLF is 1316.798608536321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hsi, the MLE is [0.04885897 1.01908722 3.11732298] and the optimized (negative) LLF is 22034.20166113898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For weekly_hsi, the MLE is [ 0.29490847 13.18079203  3.81003795] and the optimized (negative) LLF is 4459.737446190451\n",
      "For monthly_hsi, the MLE is [ 1.00200081 55.00076483  4.23246132] and the optimized (negative) LLF is 1316.7986085377956\n"
     ]
    }
   ],
   "source": [
    "keys = [\"sp500\", \"weekly_sp500\", \"monthly_sp500\", \"hsi\", \"weekly_hsi\", \"monthly_hsi\"]\n",
    "for key in keys:\n",
    "    prices = pd.read_hdf(\"data/equity-indices.h5\", key)\n",
    "    rets = 100 * prices.Close.pct_change().dropna()\n",
    "\n",
    "    mean = rets.mean()\n",
    "    var = rets.var()\n",
    "    starting_val = np.array([mean, var, 10])\n",
    "\n",
    "    bounds = [\n",
    "        (-10 * np.abs(mean), 10 * np.abs(mean)),\n",
    "        (var / 1000, 100 * var),\n",
    "        (2.05, 100),\n",
    "    ]\n",
    "    opt = minimize(\n",
    "        full_std_t_loglik,\n",
    "        starting_val,\n",
    "        args=(rets,),\n",
    "        bounds=bounds,\n",
    "    )\n",
    "    print(\n",
    "        f\"For {key}, the MLE is {opt.x} and the optimized (negative) LLF is {opt.fun}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 23\n",
    "\n",
    "Simulate a set of Bernoulli random variables $y_{i}$ where\n",
    "\n",
    "$$p_{i}=\\Phi\\left(x_{i}\\right)$$\n",
    "\n",
    "where $X_{i}\\sim N\\left(0,1\\right)$. (Note: $p_{i}$ is the probability of\n",
    "success and $\\Phi\\left(\\right)$ is the standard Normal CDF). Use this simulated data to\n",
    "estimate the Probit model where $p_{i}=\\Phi\\left(\\alpha_{0}+\\alpha_{1}x_{i}\\right)$ \n",
    "using maximum likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "nobs = 1000\n",
    "\n",
    "x = rs.standard_normal(size=nobs)\n",
    "p = stats.norm.cdf(x)\n",
    "y = 1.0 * rs.random_sample(size=nobs) < p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def probit_llf(params, y, x):\n",
    "    a0 = params[0]\n",
    "    a1 = params[1]\n",
    "    xhat = a0 + a1 * x\n",
    "    phat = stats.norm.cdf(xhat)\n",
    "\n",
    "    loglik = y * np.log(phat) + (1 - y) * np.log(1 - phat)\n",
    "    return -(loglik.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(506.6527515404093)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probit_llf([0, 1], y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLE is [-0.04581815  0.99027212]\n"
     ]
    }
   ],
   "source": [
    "starting_val = np.array([0.0, 1.0])\n",
    "opt = minimize(probit_llf, starting_val, args=(y, x))\n",
    "print(f\"The MLE is {opt.x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 24\n",
    "\n",
    "Estimate the asymptotic covariance of the estimated parameters in the previous.\n",
    "\n",
    "The derivative of the log-likelihood for a single observation is\n",
    "\n",
    "$$ \\frac{\\partial \\left\\{y_i \\ln\\left(\\Phi\\left(\\alpha_0+\\alpha_1 x_i \\right)\\right) + \\left(1-y_i\\right) \\ln\\left(1-\\Phi\\left(\\alpha_0+\\alpha_1 x_i \\right)\\right)\\right\\}}{\\partial \\alpha_j} $$\n",
    "\n",
    "which is\n",
    "\n",
    "$$ y_i \\frac{\\phi\\left(\\alpha_0+\\alpha_1 x_i \\right)}{\\Phi\\left(\\alpha_0+\\alpha_1 x_i \\right)} - \\left(1-y_i\\right)\\frac{\\phi\\left(\\alpha_0+\\alpha_1 x_i \\right)}{1-\\Phi\\left(\\alpha_0+\\alpha_1 x_i \\right)} $$\n",
    "\n",
    "for $\\alpha_0$ and \n",
    "\n",
    "$$ y_i x_i \\frac{\\phi\\left(\\alpha_0+\\alpha_1 x_i \\right)}{\\Phi\\left(\\alpha_0+\\alpha_1 x_i \\right)} - \\left(1-y_i\\right)x_i\\frac{\\phi\\left(\\alpha_0+\\alpha_1 x_i \\right)}{1-\\Phi\\left(\\alpha_0+\\alpha_1 x_i \\right)} $$\n",
    "\n",
    "for $\\alpha_1$ where $\\Phi(\\cdot)$ is the cdf of a standard Normal random variable and\n",
    "$\\phi(\\cdot)$ is the pdf of a standard Normal random variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a0</th>\n",
       "      <th>a1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a0</th>\n",
       "      <td>0.260670</td>\n",
       "      <td>-0.081185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1</th>\n",
       "      <td>-0.081185</td>\n",
       "      <td>0.130076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a0        a1\n",
       "a0  0.260670 -0.081185\n",
       "a1 -0.081185  0.130076"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = opt.x[0]\n",
    "a1 = opt.x[1]\n",
    "\n",
    "fitted = a0 + a1 * x\n",
    "pdf = stats.norm.pdf(fitted)\n",
    "cdf = stats.norm.cdf(fitted)\n",
    "\n",
    "error = y * pdf / cdf + (1 - y) * pdf * (1 - cdf)\n",
    "score = np.array([error, error * x]).T\n",
    "\n",
    "nobs = y.shape[0]\n",
    "\n",
    "asymptotic_cov = score.T @ score / nobs\n",
    "\n",
    "param_names = [\"a0\", \"a1\"]\n",
    "asymptotic_cov = pd.DataFrame(asymptotic_cov, columns=param_names, index=param_names)\n",
    "asymptotic_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a0   -0.175771\n",
       "a1    7.613041\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_stats = pd.Series(opt.x / np.diag(asymptotic_cov), index=param_names)\n",
    "t_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
