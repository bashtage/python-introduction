{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Set Construction\n",
    "\n",
    "**Functions**\n",
    "\n",
    "`pd.read_csv`, `pd.read_excel`, `np.diff` or `DataFrame.diff`, `DataFrame.resample`\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "1. Download all available daily data for the S&P 500 and the Hang Seng Index from Yahoo! Finance. \n",
    "2. Import both data sets into Python. The final dataset should have a `DateTimeIndex`, and the date\n",
    "   column should not be part of the `DataFrame`.\n",
    "3. Construct weekly price series from each, using Tuesday prices (less likely to be a holiday).\n",
    "4. Construct monthly price series from each using last day in the month.\n",
    "5. Save the data to the HDF file \"equity-indices.h5\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sp500 = pd.read_csv(\"data/GSPC.csv\", parse_dates=True, index_col=\"Date\")\n",
    "hsi = pd.read_csv(\"data/HSI.csv\", parse_dates=True, index_col=\"Date\")\n",
    "\n",
    "weekly_sp500 = sp500.resample(\"W-TUE\").last()\n",
    "weekly_hsi = hsi.resample(\"W-TUE\").last()\n",
    "\n",
    "monthly_sp500 = sp500.resample(\"M\").last()\n",
    "monthly_hsi = hsi.resample(\"M\").last()\n",
    "\n",
    "h5file = pd.HDFStore(\"data/equity-indices.h5\", mode=\"w\")\n",
    "h5file.append(\"sp500\", sp500)\n",
    "h5file.append(\"weekly_sp500\", weekly_sp500)\n",
    "h5file.append(\"monthly_sp500\", monthly_sp500)\n",
    "h5file.append(\"hsi\", sp500)\n",
    "h5file.append(\"weekly_hsi\", weekly_hsi)\n",
    "h5file.append(\"monthly_hsi\", monthly_hsi)\n",
    "h5file.close()\n",
    "\n",
    "sp500.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sp500.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sp500.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write a function that will correctly aggregate to weekly or monthly respecting the\n",
    "aggregation rules\n",
    "\n",
    "* High: `max`\n",
    "* Low: `min`\n",
    "* Volume: `sum`\n",
    "\n",
    "The signature should be:\n",
    "\n",
    "```python\n",
    "def yahoo_agg(data, freq):\n",
    "    <code here>\n",
    "    return resampled_data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yahoo_agg(data, freq):\n",
    "    resampler = data.resample(freq)\n",
    "\n",
    "    high = resampler.High.max()\n",
    "    low = resampler.Low.min()\n",
    "    vol = resampler.Volume.sum()\n",
    "    # Start with last for all columns\n",
    "    resampled_data = resampler.last()\n",
    "    # Insert columns that use a different rule\n",
    "    resampled_data[\"High\"] = high\n",
    "    resampled_data[\"Low\"] = low\n",
    "    resampled_data[\"Volume\"] = vol\n",
    "\n",
    "    return resampled_data\n",
    "\n",
    "\n",
    "better_monthly_sp500 = yahoo_agg(sp500, \"M\")\n",
    "\n",
    "monthly_sp500[[\"High\", \"Low\", \"Volume\"]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_monthly_sp500[[\"High\", \"Low\", \"Volume\"]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "1. Import the Fama-French benchmark portfolios as well as the 25 sorted portfolios at both the\n",
    "   monthly and daily horizon from [Ken French\"s Data Library](http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html).\n",
    "   **Note** It is much easier to clean to data file before importing than to find the precise\n",
    "   command that will load the unmodified data.\n",
    "2. Import daily FX rate data for USD against AUD, Euro, JPY and GBP from the [Federal Reserve Economic Database (FRED)](http://research.stlouisfed.org/fred2/categories/94). Use Excel (xls) rather than csv files.\n",
    "3. Save the data to the HDF files \"fama-french.h5\" and \"fx.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yen_dollar = pd.read_excel(\n",
    "    \"data/DEXJPUS.xls\", index_col=\"observation_date\", skiprows=10\n",
    ")\n",
    "dollar_aud = pd.read_excel(\n",
    "    \"data/DEXUSAL.xls\", index_col=\"observation_date\", skiprows=10\n",
    ")\n",
    "dollar_euro = pd.read_excel(\n",
    "    \"data/DEXUSEU.xls\", index_col=\"observation_date\", skiprows=10\n",
    ")\n",
    "dollar_pound = pd.read_excel(\n",
    "    \"data/DEXUSUK.xls\", index_col=\"observation_date\", skiprows=10\n",
    ")\n",
    "\n",
    "fx = pd.concat([yen_dollar, dollar_aud, dollar_euro, dollar_pound], axis=1)\n",
    "print(fx.tail())\n",
    "fx.to_hdf(\"data/fx.h5\", \"fx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files have all been cleaned to have only the data and headers\n",
    "ff_5x5 = pd.read_csv(\"data/25_Portfolios_5x5.CSV\", index_col=0)\n",
    "ff_factors = pd.read_csv(\"data/F-F_Research_Data_Factors.CSV\", index_col=0)\n",
    "ff = pd.concat([ff_factors, ff_5x5], axis=1)\n",
    "\n",
    "dates = []\n",
    "for value in ff.index:\n",
    "    # Values are YYYYMM\n",
    "    year = value // 100\n",
    "    month = value % 100\n",
    "    dates.append(pd.Timestamp(year=year, month=month, day=1))\n",
    "ff.index = dates\n",
    "ff.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a \"trick\" to get the index to have the last day in the month.\n",
    "ff = ff.resample(\"M\").last()\n",
    "\n",
    "ff.to_hdf(\"data/ff.h5\", \"ff\")\n",
    "\n",
    "ff.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files have all been cleaned to have only the data and headers\n",
    "ff_5x5_daily = pd.read_csv(\"data/25_Portfolios_5x5_daily.CSV\", index_col=0)\n",
    "ff_factors_daily = pd.read_csv(\"data/F-F_Research_Data_Factors_daily.CSV\", index_col=0)\n",
    "ff_daily = pd.concat([ff_factors_daily, ff_5x5_daily], axis=1)\n",
    "\n",
    "\n",
    "dates = []\n",
    "for value in ff_daily.index:\n",
    "    # Values are YYYYMMDD\n",
    "    year = value // 10000\n",
    "    month = (value // 100) % 100\n",
    "    day = value % 100\n",
    "    dates.append(pd.Timestamp(year=year, month=month, day=day))\n",
    "ff_daily.index = dates\n",
    "ff_daily.to_hdf(\"data/ff_daily.h5\", \"ff_daily\")\n",
    "\n",
    "ff_daily.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 (Alternative method)\n",
    "\n",
    "1. Install and use `pandas-datareader` to repeat the previous exercise.\n",
    "\n",
    "#### Preliminary Step\n",
    "\n",
    "You must first install the module using \n",
    "\n",
    "```\n",
    "pip install pandas-datareader\n",
    "``` \n",
    "\n",
    "from the command line. Then you can run this code. **Note**: Running this code requires access\n",
    "to the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "\n",
    "# Conservative start date to get all data\n",
    "yen_dollar = pdr.get_data_fred(\"DEXJPUS\", start=\"1950\")\n",
    "dollar_aud = pdr.get_data_fred(\"DEXUSAL\", start=\"1950\")\n",
    "dollar_euro = pdr.get_data_fred(\"DEXUSEU\", start=\"1950\")\n",
    "dollar_pound = pdr.get_data_fred(\"DEXUSUK\", start=\"1950\")\n",
    "fx = pd.concat([yen_dollar, dollar_aud, dollar_euro, dollar_pound], axis=1)\n",
    "fx.to_hdf(\"data/fx-pdr.h5\", \"fx\")\n",
    "fx.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_factors = pdr.get_data_famafrench(\"F-F_Research_Data_Factors\", start=\"1920\")\n",
    "ff_5x5 = pdr.get_data_famafrench(\"25_Portfolios_5x5\", start=\"1920\")\n",
    "# The function returns all of the tables in each file.  We want the first, [0]\n",
    "ff_factors = ff_factors[0]\n",
    "ff_5x5 = ff_5x5[0]\n",
    "ff = pd.concat([ff_factors, ff_5x5], axis=1)\n",
    "ff.to_hdf(\"data/ff-pdr.h5\", \"ff\")\n",
    "ff.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 4\n",
    "Download data on 1 year and 10 year US government bond rates from FRED, and \n",
    "construct the term premium as the different in yields on 10 year and 1 year\n",
    "bonds. Combine the two yield series and the term premium into a `DataFrame`\n",
    "and save it as HDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to import here since pandas and pandas-datareader previously imported\n",
    "\n",
    "# Conservative start date to get all data\n",
    "gs10 = pdr.get_data_fred(\"GS10\", start=\"1950\")\n",
    "gs1 = pdr.get_data_fred(\"GS1\", start=\"1950\")\n",
    "\n",
    "term = gs10[\"GS10\"] - gs1[\"GS1\"]\n",
    "term.name = \"TERM\"\n",
    "combined = pd.DataFrame([term, gs10[\"GS10\"], gs1[\"GS1\"]]).T\n",
    "combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick to ensure the index has the frequency MS, Month Start\n",
    "combined = combined.resample(\"MS\").last()\n",
    "combined.to_hdf(\"data/term-premium.h5\", \"term_premium\")\n",
    "combined.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
